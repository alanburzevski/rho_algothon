{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "2a4da8a39c352f5ede24ff792aa7ccf1d4bef812746241a0a0f53708014881b5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Importing packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.arima.model import ARIMA"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Reading data\n",
    "dataRaw = pd.read_csv('./prices250.txt', delimiter = '\\s+', header = None).T\n",
    "\n",
    "## Adding column names (for each timepoint)\n",
    "dataRaw.columns = ['price' + str(x) for x in range(1, dataRaw.shape[1]+1, 1)]\n",
    "\n",
    "## Adding column representing which instrument\n",
    "dataRaw['instrument'] = ['instrument' + str(x) for x in range(1, dataRaw.shape[0]+1, 1)]\n",
    "\n",
    "## Converting to long format\n",
    "data = pd.wide_to_long(dataRaw, stubnames = 'price', i = 'instrument', j = 'time')\n",
    "data['instrument'] = [x[0] for x in data.index]\n",
    "data['time'] = [x[1] for x in data.index]\n",
    "data.reset_index(drop = True, inplace = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Autocorrelation graph\n",
    "\n",
    "for i in range(1, 101, 1):\n",
    "    instrument = data[data['instrument'] == ('instrument' + str(i))]['price']\n",
    "    pd.plotting.autocorrelation_plot(instrument, linewidth = 0.5)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Instrument 1 ARIMA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Subset for testing\n",
    "\n",
    "dataInstrument1 = data[data[\"instrument\"] == \"instrument1\"][[\"price\", \"time\"]].set_index(\"time\")\n",
    "dataInstrument1.index = pd.to_datetime(dataInstrument1.index, unit = 'd')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Looking for optimal ARIMA parameters\n",
    "\n",
    "# trainData = dataInstrument1[\"price\"][:225]\n",
    "# testData = dataInstrument1[\"price\"][225:]\n",
    "\n",
    "# p = range(30, 31, 1)\n",
    "# d = q = range(0, 2)\n",
    "# pdq = list(itertools.product(p, d, q))\n",
    "# modelAIC = []\n",
    "\n",
    "# for paramlist in pdq:\n",
    "#     arimaModel = ARIMA(trainData, order = paramlist)\n",
    "#     arimaModelFit = arimaModel.fit()\n",
    "#     modelAIC.append(arimaModelFit.aic)\n",
    "\n",
    "# for i in range(len(modelAIC)):\n",
    "#     if list(modelAIC == min(modelAIC))[i] == True:\n",
    "#         print(pdq[i])"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Training using optimised parameters\n",
    "\n",
    "trainData = dataInstrument1[\"price\"][:225]\n",
    "testData = dataInstrument1[\"price\"][225:]\n",
    "arimaModel = ARIMA(trainData, order = (30, 1, 0))\n",
    "arimaModelFit = arimaModel.fit()\n",
    "predictions = arimaModelFit.forecast(steps = 25)\n",
    "\n",
    "testData.plot()\n",
    "predictions.plot(color = \"red\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortTermTrading(instrumentData, params, days, prevPosition):\n",
    "    \n",
    "    # Fitting ARIMA and predicting specified number of days\n",
    "    arimaModel = ARIMA(instrumentData, order = params)\n",
    "    arimaModelFit = arimaModel.fit()\n",
    "    predictions = arimaModelFit.forecast(steps = days)\n",
    "\n",
    "    # Only looking at observations within specified window\n",
    "    instrumentDataWindow = instrumentData.iloc[0:days, :]\n",
    "    \n",
    "    # Obtaining prices and days within window with minimum and maximum days\n",
    "    priceMin = [x == min(predictions) for x in predictions]\n",
    "    priceMax = [x == max(predictions) for x in predictions]\n",
    "    days = [x for x in range(0, days, 1)]\n",
    "    dayMin = list(itertools.compress(days, priceMin))[0]\n",
    "    dayMax = list(itertools.compress(days, priceMax))[0]\n",
    "\n",
    "    # Obtaining lists of minimum and maximum days, prices, and non-minimum or maximum days\n",
    "    minMaxDays = [dayMin, dayMax]\n",
    "    minMaxPrice = list(instrumentDataWindow.iloc[minMaxDays, 0])\n",
    "    otherDays = np.setdiff1d(days, minMaxDays)\n",
    "\n",
    "    # Obtaining position\n",
    "    position = np.full(shape = (10, 1), fill_value = prevPosition[-1]) # initial position all 0\n",
    "    position[minMaxDays[0]] = -5000/minMaxPrice[0]\n",
    "    position[minMaxDays[1]] = 5000/minMaxPrice[1]\n",
    "    for i in otherDays: # all other days reflect previous day's position\n",
    "        position[i] = position[i-1]\n",
    "\n",
    "    return position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortTermTrading(instrumentData = dataInstrument1, params = (30, 1, 0), days = 10, prevPosition = position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/alanburzevski/Documents/Uni/casecomp/rho_algothon/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/alanburzevski/Documents/Uni/casecomp/rho_algothon/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/alanburzevski/Documents/Uni/casecomp/rho_algothon/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/alanburzevski/Documents/Uni/casecomp/rho_algothon/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/alanburzevski/Documents/Uni/casecomp/rho_algothon/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/alanburzevski/Documents/Uni/casecomp/rho_algothon/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/alanburzevski/Documents/Uni/casecomp/rho_algothon/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/alanburzevski/Documents/Uni/casecomp/rho_algothon/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/alanburzevski/Documents/Uni/casecomp/rho_algothon/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/alanburzevski/Documents/Uni/casecomp/rho_algothon/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/alanburzevski/Documents/Uni/casecomp/rho_algothon/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/alanburzevski/Documents/Uni/casecomp/rho_algothon/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  warnings.warn('No frequency information was'\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[   0.        ],\n",
       "       [   0.        ],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [-271.88689505],\n",
       "       [-271.88689505],\n",
       "       [-271.88689505],\n",
       "       [-271.88689505],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [-271.88689505],\n",
       "       [-271.88689505],\n",
       "       [-271.88689505],\n",
       "       [-271.88689505],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [-271.88689505],\n",
       "       [-271.88689505],\n",
       "       [-271.88689505],\n",
       "       [-271.88689505],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [-271.88689505],\n",
       "       [-271.88689505],\n",
       "       [-271.88689505]])"
      ]
     },
     "metadata": {},
     "execution_count": 401
    }
   ],
   "source": [
    "position = np.zeros(shape = (1,1))\n",
    "i = 1\n",
    "while i < 5:\n",
    "    \n",
    "    newPosition = shortTermTrading(instrumentData = dataInstrument1, params = (30, 1, 0), days = 10, prevPosition = position)\n",
    "    position = np.concatenate((position, newPosition), axis=0)\n",
    "\n",
    "    i = i+1\n",
    "\n",
    "position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = np.zeros(shape = (10, 1))\n",
    "minmax_price = shortTermTrading(instrumentData = dataInstrument1, params = (30, 1, 0), days = 10)\n",
    "position[minmax_price[0][0]] = -5000/minmax_price[1][0]\n",
    "position[minmax_price[0][1]] = 5000/minmax_price[1][1]\n",
    "\n",
    "for i in minmax_price[2]:\n",
    "    position[i] = position[i-1]\n",
    "\n",
    "position"
   ]
  },
  {
   "source": [
    "## Modern Portfolio Theory Implementation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global constants / variables\n",
    "nDays = 250\n",
    "nInst = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reads in first 250 days' data into numpy array givenPrices\n",
    "# Input: N/A\n",
    "# Output: matrix of price history from training data\n",
    "def readTraining ():\n",
    "    f = open(\"prices250.txt\", \"r\")\n",
    "    givenPrices = []\n",
    "    for line in f:\n",
    "        row = [float(num) for num in line.split()]\n",
    "        givenPrices.append(row)\n",
    "    givenPrices = np.array(givenPrices)\n",
    "    # print(givenPrices.shape)\n",
    "    return givenPrices\n",
    "\n",
    "# Given the price history, output daily percentage price change matrix\n",
    "# Input: givenPrices (price history)\n",
    "# Output: matrix of daily percentage change; dailyReturns[i-1][j-1] = percentage change of instrument j between days i and i-1\n",
    "def dailyReturns (givenPrices):\n",
    "    logChange = []\n",
    "    # loop through each instrument\n",
    "    for inst in givenPrices.T:\n",
    "        logChangeInst = np.empty((nDays, 1))\n",
    "        # logChangeInst = np.zeros(nDays)\n",
    "        for day in range(0, nDays - 1):\n",
    "            logChangeInst[day] = np.log(inst[day + 1] / inst[day])\n",
    "        logChange.append(logChangeInst)\n",
    "    logChange = np.array(logChange)\n",
    "    # print(logChange.T.shape)\n",
    "    return logChange.T\n",
    "\n",
    "# Given the daily price changes, output the avg. daily return, SD, variance for each instrument\n",
    "def returnMeasures (dailyReturns):\n",
    "    measures = np.empty((3, nInst))\n",
    "    measures[0] = [np.average(inst) for inst in dailyReturns.T]\n",
    "    measures[1] = [np.std(inst, ddof=1) for inst in dailyReturns.T]\n",
    "    measures[2] = [np.var(inst, ddof=1) for inst in dailyReturns.T]\n",
    "    return measures\n",
    "\n",
    "# Given the price history, output the excess returns matrix\n",
    "# Input: givenPrices (price history)\n",
    "# Output: matrix of excess returns; excessReturns[i-1][j-1] = excess returns of instrument j on day i\n",
    "def excessReturns (givenPrices):\n",
    "    excessReturns = []\n",
    "    # get the required matrices for further computation\n",
    "    Returns = dailyReturns(givenPrices)\n",
    "    measures = returnMeasures(Returns)\n",
    "\n",
    "    for inst in range(nInst):\n",
    "        instExcess = np.empty(nDays - 1) \n",
    "        instReturns = (Returns.T)[inst]\n",
    "        for i in range (0, nDays - 1):\n",
    "            instExcess[i] = instReturns[i] - measures[0][inst]\n",
    "        excessReturns.append(instExcess)\n",
    "\n",
    "    excessReturns = np.array(excessReturns)\n",
    "    print(excessReturns.T.shape)\n",
    "    return excessReturns.T\n",
    "\n",
    "# Calculate the variance covariance matrix\n",
    "# Input: excess returns\n",
    "# Output: variance covariance matrix\n",
    "def varCov (givenExcess):\n",
    "    varCovMat = np.matmul(givenExcess.T, givenExcess)/(249 - 1) # -1 because sample std\n",
    "    return varCovMat\n",
    "\n",
    "# Calculate the scaled variance covariance matrix\n",
    "# Input: variance covariance matrix\n",
    "# Output: scaled variance covariance matrix\n",
    "def sigma (varCovMat):\n",
    "    sigmaMat = varCovMat*250\n",
    "    return sigmaMat\n",
    "\n",
    "# Calculate weights\n",
    "# Input: average returns, inverse scaled variance covariance matrix, and target returns\n",
    "# Output: weights for optimal portfolio given target returns\n",
    "def getWeights(returns, inverseSigma, targetReturn):\n",
    "    ones = np.ones(nInst)\n",
    "    A = np.matmul(np.matmul(ones, inverseSigma), ones.T)\n",
    "    B = np.matmul(np.matmul(ones, inverseSigma), returns.T)\n",
    "    C = np.matmul(np.matmul(returns, inverseSigma), returns.T)\n",
    "    delta = A * C - B**2\n",
    "    lam = (C - targetReturn*B)/delta\n",
    "    gam = (targetReturn*A - B)/delta\n",
    "\n",
    "    weightsTerm1 = lam * np.matmul(inverseSigma, ones.T)\n",
    "    weightsTerm2 = gam * np.matmul(inverseSigma, returns.T)\n",
    "    weights = weightsTerm1 + weightsTerm2\n",
    "    return(weights)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test to get weights\n",
    "\n",
    "returns = returnMeasures(dailyReturns(readTraining()))[0]*250\n",
    "inverseSigma = np.linalg.inv(sigma(varCov(excessReturns(readTraining()))))\n",
    "targetReturn = 0.05\n",
    "getWeights(returns, sigma, targetReturn)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}