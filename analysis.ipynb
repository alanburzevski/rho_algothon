{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "2a4da8a39c352f5ede24ff792aa7ccf1d4bef812746241a0a0f53708014881b5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Importing packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.arima.model import ARIMA"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Reading data\n",
    "dataRaw = pd.read_csv('./prices250.txt', delimiter = '\\s+', header = None).T\n",
    "\n",
    "## Adding column names (for each timepoint)\n",
    "dataRaw.columns = ['price' + str(x) for x in range(1, dataRaw.shape[1]+1, 1)]\n",
    "\n",
    "## Adding column representing which instrument\n",
    "dataRaw['instrument'] = ['instrument' + str(x) for x in range(1, dataRaw.shape[0]+1, 1)]\n",
    "\n",
    "## Converting to long format\n",
    "data = pd.wide_to_long(dataRaw, stubnames = 'price', i = 'instrument', j = 'time')\n",
    "data['instrument'] = [x[0] for x in data.index]\n",
    "data['time'] = [x[1] for x in data.index]\n",
    "data.reset_index(drop = True, inplace = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Autocorrelation graph\n",
    "\n",
    "for i in range(1, 101, 1):\n",
    "    instrument = data[data['instrument'] == ('instrument' + str(i))]['price']\n",
    "    pd.plotting.autocorrelation_plot(instrument, linewidth = 0.5)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Instrument 1 ARIMA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Subset for testing\n",
    "\n",
    "dataInstrument1 = data[data[\"instrument\"] == \"instrument1\"][[\"price\", \"time\"]].set_index(\"time\")\n",
    "dataInstrument1.index = pd.to_datetime(dataInstrument1.index, unit = 'd')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Looking for optimal ARIMA parameters\n",
    "\n",
    "# trainData = dataInstrument1[\"price\"][:225]\n",
    "# testData = dataInstrument1[\"price\"][225:]\n",
    "\n",
    "# p = range(30, 31, 1)\n",
    "# d = q = range(0, 2)\n",
    "# pdq = list(itertools.product(p, d, q))\n",
    "# modelAIC = []\n",
    "\n",
    "# for paramlist in pdq:\n",
    "#     arimaModel = ARIMA(trainData, order = paramlist)\n",
    "#     arimaModelFit = arimaModel.fit()\n",
    "#     modelAIC.append(arimaModelFit.aic)\n",
    "\n",
    "# for i in range(len(modelAIC)):\n",
    "#     if list(modelAIC == min(modelAIC))[i] == True:\n",
    "#         print(pdq[i])"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Training using optimised parameters\n",
    "\n",
    "trainData = dataInstrument1[\"price\"][:225]\n",
    "testData = dataInstrument1[\"price\"][225:]\n",
    "arimaModel = ARIMA(trainData, order = (30, 1, 0))\n",
    "arimaModelFit = arimaModel.fit()\n",
    "predictions = arimaModelFit.forecast(steps = 25)\n",
    "\n",
    "testData.plot()\n",
    "predictions.plot(color = \"red\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortTermTrading(instrumentData, params, window, prevPosition):\n",
    "    \n",
    "    # Fitting ARIMA and predicting specified number of days\n",
    "    arimaModel = ARIMA(instrumentData, order = params)\n",
    "    arimaModelFit = arimaModel.fit()\n",
    "    predictions = arimaModelFit.forecast(steps = window)\n",
    "\n",
    "    # Only looking at observations within specified window\n",
    "    instrumentDataWindow = instrumentData.iloc[0:window, :]\n",
    "    \n",
    "    # Obtaining prices and days within window with minimum and maximum days\n",
    "    priceMin = [x == min(predictions) for x in predictions]\n",
    "    priceMax = [x == max(predictions) for x in predictions]\n",
    "    days = [x for x in range(0, window, 1)]\n",
    "    dayMin = list(itertools.compress(days, priceMin))[0]\n",
    "    dayMax = list(itertools.compress(days, priceMax))[0]\n",
    "\n",
    "    # Obtaining lists of minimum and maximum days, prices, and non-minimum or maximum days\n",
    "    minMaxDays = [dayMin, dayMax]\n",
    "    minMaxPrice = list(instrumentDataWindow.iloc[minMaxDays, 0])\n",
    "    otherDays = np.setdiff1d(days, minMaxDays)\n",
    "\n",
    "    # Obtaining position\n",
    "    position = np.full(shape = (window, 1), fill_value = prevPosition[-1]) # initial position all 0\n",
    "    position[minMaxDays[0]] = -5000/minMaxPrice[0]\n",
    "    position[minMaxDays[1]] = 5000/minMaxPrice[1]\n",
    "    for i in otherDays: # all other days reflect previous day's position\n",
    "        try:\n",
    "            position[i] = position[i-1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/alanburzevski/Documents/Uni/casecomp/rho_algothon/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n  warnings.warn('No frequency information was'\n/Users/alanburzevski/Documents/Uni/casecomp/rho_algothon/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n  warnings.warn('No frequency information was'\n/Users/alanburzevski/Documents/Uni/casecomp/rho_algothon/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n  warnings.warn('No frequency information was'\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[   0],\n",
       "       [ 274],\n",
       "       [ 274],\n",
       "       [ 274],\n",
       "       [ 274],\n",
       "       [ 274],\n",
       "       [ 274],\n",
       "       [-271],\n",
       "       [-271],\n",
       "       [-271]])"
      ]
     },
     "metadata": {},
     "execution_count": 440
    }
   ],
   "source": [
    "shortTermTrading(instrumentData = dataInstrument1, params = (30, 1, 0), window = 10, prevPosition = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/alanburzevski/Documents/Uni/casecomp/rho_algothon/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/alanburzevski/Documents/Uni/casecomp/rho_algothon/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/alanburzevski/Documents/Uni/casecomp/rho_algothon/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/alanburzevski/Documents/Uni/casecomp/rho_algothon/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/alanburzevski/Documents/Uni/casecomp/rho_algothon/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/alanburzevski/Documents/Uni/casecomp/rho_algothon/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/alanburzevski/Documents/Uni/casecomp/rho_algothon/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/alanburzevski/Documents/Uni/casecomp/rho_algothon/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/alanburzevski/Documents/Uni/casecomp/rho_algothon/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/alanburzevski/Documents/Uni/casecomp/rho_algothon/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/alanburzevski/Documents/Uni/casecomp/rho_algothon/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  warnings.warn('No frequency information was'\n",
      "/Users/alanburzevski/Documents/Uni/casecomp/rho_algothon/venv/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:524: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  warnings.warn('No frequency information was'\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[   0.        ],\n",
       "       [   0.        ],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [-271.88689505],\n",
       "       [-271.88689505],\n",
       "       [-271.88689505],\n",
       "       [-271.88689505],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [-271.88689505],\n",
       "       [-271.88689505],\n",
       "       [-271.88689505],\n",
       "       [-271.88689505],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [-271.88689505],\n",
       "       [-271.88689505],\n",
       "       [-271.88689505],\n",
       "       [-271.88689505],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [ 274.42371021],\n",
       "       [-271.88689505],\n",
       "       [-271.88689505],\n",
       "       [-271.88689505]])"
      ]
     },
     "metadata": {},
     "execution_count": 401
    }
   ],
   "source": [
    "position = np.zeros(shape = (1,1))\n",
    "i = 1\n",
    "while i < 5:\n",
    "    \n",
    "    newPosition = shortTermTrading(instrumentData = dataInstrument1, params = (30, 1, 0), days = 10, prevPosition = position)\n",
    "    position = np.concatenate((position, newPosition), axis=0)\n",
    "\n",
    "    i = i+1\n",
    "\n",
    "position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = np.zeros(shape = (10, 1))\n",
    "minmax_price = shortTermTrading(instrumentData = dataInstrument1, params = (30, 1, 0), days = 10)\n",
    "position[minmax_price[0][0]] = -5000/minmax_price[1][0]\n",
    "position[minmax_price[0][1]] = 5000/minmax_price[1][1]\n",
    "\n",
    "for i in minmax_price[2]:\n",
    "    position[i] = position[i-1]\n",
    "\n",
    "position"
   ]
  },
  {
   "source": [
    "## Modern Portfolio Theory Implementation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global constants / variables\n",
    "nDays = 250\n",
    "nInst = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reads in first 250 days' data into numpy array givenPrices\n",
    "# Input: N/A\n",
    "# Output: matrix of price history from training data\n",
    "def readTraining ():\n",
    "    f = open(\"prices250.txt\", \"r\")\n",
    "    givenPrices = []\n",
    "    for line in f:\n",
    "        row = [float(num) for num in line.split()]\n",
    "        givenPrices.append(row)\n",
    "    givenPrices = np.array(givenPrices)\n",
    "    # print(givenPrices.shape)\n",
    "    return givenPrices\n",
    "\n",
    "# Given the price history, output daily percentage price change matrix\n",
    "# Input: givenPrices (price history)\n",
    "# Output: matrix of daily percentage change; dailyReturns[i-1][j-1] = percentage change of instrument j between days i and i-1\n",
    "def dailyReturns (givenPrices):\n",
    "    logChange = []\n",
    "    # loop through each instrument\n",
    "    for inst in givenPrices.T:\n",
    "        logChangeInst = np.empty((nDays, 1))\n",
    "        # logChangeInst = np.zeros(nDays)\n",
    "        for day in range(0, nDays - 1):\n",
    "            logChangeInst[day] = np.log(inst[day + 1] / inst[day])\n",
    "        logChange.append(logChangeInst)\n",
    "    logChange = np.array(logChange)\n",
    "    # print(logChange.T.shape)\n",
    "    return logChange.T\n",
    "\n",
    "# Given the daily price changes, output the avg. daily return, SD, variance for each instrument\n",
    "def returnMeasures (dailyReturns):\n",
    "    measures = np.empty((3, nInst))\n",
    "    measures[0] = [np.average(inst) for inst in dailyReturns.T]\n",
    "    measures[1] = [np.std(inst, ddof=1) for inst in dailyReturns.T]\n",
    "    measures[2] = [np.var(inst, ddof=1) for inst in dailyReturns.T]\n",
    "    return measures\n",
    "\n",
    "# Given the price history, output the excess returns matrix\n",
    "# Input: givenPrices (price history)\n",
    "# Output: matrix of excess returns; excessReturns[i-1][j-1] = excess returns of instrument j on day i\n",
    "def excessReturns (givenPrices):\n",
    "    excessReturns = []\n",
    "    # get the required matrices for further computation\n",
    "    Returns = dailyReturns(givenPrices)\n",
    "    measures = returnMeasures(Returns)\n",
    "\n",
    "    for inst in range(nInst):\n",
    "        instExcess = np.empty(nDays - 1) \n",
    "        instReturns = (Returns.T)[inst]\n",
    "        for i in range (0, nDays - 1):\n",
    "            instExcess[i] = instReturns[i] - measures[0][inst]\n",
    "        excessReturns.append(instExcess)\n",
    "\n",
    "    excessReturns = np.array(excessReturns)\n",
    "    print(excessReturns.T.shape)\n",
    "    return excessReturns.T\n",
    "\n",
    "# Calculate the variance covariance matrix\n",
    "# Input: excess returns\n",
    "# Output: variance covariance matrix\n",
    "def varCov (givenExcess):\n",
    "    varCovMat = np.matmul(givenExcess.T, givenExcess)/(249 - 1) # -1 because sample std\n",
    "    return varCovMat\n",
    "\n",
    "# Calculate the scaled variance covariance matrix\n",
    "# Input: variance covariance matrix\n",
    "# Output: scaled variance covariance matrix\n",
    "def sigma (varCovMat):\n",
    "    sigmaMat = varCovMat*250\n",
    "    return sigmaMat\n",
    "\n",
    "# Calculate weights\n",
    "# Input: average returns, inverse scaled variance covariance matrix, and target returns\n",
    "# Output: weights for optimal portfolio given target returns\n",
    "def getWeights(returns, inverseSigma, targetReturn):\n",
    "    ones = np.ones(nInst)\n",
    "    A = np.matmul(np.matmul(ones, inverseSigma), ones.T)\n",
    "    B = np.matmul(np.matmul(ones, inverseSigma), returns.T)\n",
    "    C = np.matmul(np.matmul(returns, inverseSigma), returns.T)\n",
    "    delta = A * C - B**2\n",
    "    lam = (C - targetReturn*B)/delta\n",
    "    gam = (targetReturn*A - B)/delta\n",
    "\n",
    "    weightsTerm1 = lam * np.matmul(inverseSigma, ones.T)\n",
    "    weightsTerm2 = gam * np.matmul(inverseSigma, returns.T)\n",
    "    weights = weightsTerm1 + weightsTerm2\n",
    "    return(weights)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test to get weights\n",
    "\n",
    "returns = returnMeasures(dailyReturns(readTraining()))[0]*250\n",
    "inverseSigma = np.linalg.inv(sigma(varCov(excessReturns(readTraining()))))\n",
    "targetReturn = 0.05\n",
    "getWeights(returns, sigma, targetReturn)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-0.31455399, -0.10574558, -0.05566734, -0.4987704 , -0.75631567,\n",
       "       -0.40532081, -0.65302929, -0.37402191,  0.15582383, -0.61457635,\n",
       "        0.2309412 , -0.40129667, -0.22244579, -0.58014755, -0.49474626,\n",
       "       -0.34182875, -0.20903197, -0.30695283, -0.43617259, -0.36373798,\n",
       "       -0.52380952, -0.00156495, -0.19740666, -0.44019674, -0.37849318,\n",
       "       -0.43661972,  1.        , -0.35568969, -0.32662643, -0.37581042,\n",
       "       -0.13793874, -0.38877711, -0.2456964 , -0.21886877, -0.40308518,\n",
       "       -0.45226917, -0.54393025, -0.43483121,  0.01184887, -0.38162307,\n",
       "       -0.35613682, -0.16879052, -1.        , -0.29622178, -0.26671138,\n",
       "       -0.27252403, -0.64363962, -0.56136821, -0.31008272, -0.62799016,\n",
       "       -0.41247485, -0.40487369, -0.41158059, -0.43035994, -0.43840823,\n",
       "       -0.43170132, -0.43885535, -0.4527163 , -0.37312765, -0.4133691 ,\n",
       "       -0.43214845, -0.4379611 , -0.45048066, -0.40576794, -0.42186452,\n",
       "       -0.40129667, -0.44243237, -0.4330427 , -0.41694612, -0.41515761,\n",
       "       -0.41739325, -0.40532081, -0.41515761, -0.43170132, -0.42678292,\n",
       "       -0.41694612, -0.43035994, -0.44064386, -0.4232059 , -0.42499441,\n",
       "       -0.44243237, -0.43527834, -0.42588867, -0.43214845, -0.4182875 ,\n",
       "       -0.4379611 , -0.42588867, -0.39056562, -0.45539906, -0.38832998,\n",
       "       -0.44332663, -0.39637827, -0.41560474, -0.40889783, -0.44511514,\n",
       "       -0.42857143, -0.39816678, -0.39593114, -0.42946568, -0.43348983])"
      ]
     },
     "metadata": {},
     "execution_count": 423
    }
   ],
   "source": [
    "def minmaxTransform(OldValue, NewMin, NewMax):\n",
    "    OldMax = max(OldValue)\n",
    "    OldMin = min(OldValue)\n",
    "\n",
    "    newValue = np.zeros(len(OldValue))\n",
    "    for index, value in enumerate(OldValue):\n",
    "        newValue[index] = (((value - OldMin) * (NewMax - NewMin)) / (OldMax - OldMin)) + NewMin\n",
    "\n",
    "    return newValue\n",
    "\n",
    "weights = [2.38, 7.05, 8.17, -1.74, -7.50, 0.35, -5.19, 1.05, 12.90, -4.33, 14.58, 0.44, 4.44, -3.56, -1.65, 1.77, 4.74, 2.55, -0.34, 1.28, -2.30, 9.38, 5.00, -0.43, 0.95, -0.35, 31.78, 1.46, 2.11, 1.01, 6.33, 0.72, 3.92, 4.52, 0.40, -0.70, -2.75, -0.31, 9.68, 0.88, 1.45, 5.64, -12.95, 2.79, 3.45, 3.32, -4.98, -3.14, 2.48, -4.63, 0.19, 0.36, 0.21, -0.21, -0.39, -0.24, -0.40, -0.71, 1.07, 0.17, -0.25, -0.38, -0.66, 0.34, -0.02, 0.44, -0.48, -0.27, 0.09, 0.13, 0.08, 0.35, 0.13, -0.24, -0.13, 0.09, -0.21, -0.44, -0.05, -0.09, -0.48, -0.32, -0.11, -0.25, 0.06, -0.38, -0.11, 0.68, -0.77, 0.73, -0.50, 0.55, 0.12, 0.27, -0.54, -0.17, 0.51, 0.56, -0.19, -0.28]\n",
    "\n",
    "transformWeights = minmaxTransform(weights, -1, 1)\n",
    "longHoldings = transformWeights\n",
    "\n",
    "longHoldings"
   ]
  }
 ]
}