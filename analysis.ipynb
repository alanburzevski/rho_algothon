{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "2a4da8a39c352f5ede24ff792aa7ccf1d4bef812746241a0a0f53708014881b5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Importing packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.arima.model import ARIMA"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Reading data\n",
    "dataRaw = pd.read_csv('./prices250.txt', delimiter = '\\s+', header = None).T\n",
    "\n",
    "## Adding column names (for each timepoint)\n",
    "dataRaw.columns = ['price' + str(x) for x in range(1, dataRaw.shape[1]+1, 1)]\n",
    "\n",
    "## Adding column representing which instrument\n",
    "dataRaw['instrument'] = ['instrument' + str(x) for x in range(1, dataRaw.shape[0]+1, 1)]\n",
    "\n",
    "## Converting to long format\n",
    "data = pd.wide_to_long(dataRaw, stubnames = 'price', i = 'instrument', j = 'time')\n",
    "data['instrument'] = [x[0] for x in data.index]\n",
    "data['time'] = [x[1] for x in data.index]\n",
    "data.reset_index(drop = True, inplace = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Autocorrelation graph\n",
    "\n",
    "for i in range(1, 101, 1):\n",
    "    instrument = data[data['instrument'] == ('instrument' + str(i))]['price']\n",
    "    pd.plotting.autocorrelation_plot(instrument, linewidth = 0.5)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Instrument 1 ARIMA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Subset for testing\n",
    "\n",
    "dataInstrument1 = data[data[\"instrument\"] == \"instrument1\"][[\"price\", \"time\"]].set_index(\"time\")\n",
    "dataInstrument1.index = pd.to_datetime(dataInstrument1.index, unit = 'd')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Looking for optimal ARIMA parameters\n",
    "\n",
    "# trainData = dataInstrument1[\"price\"][:225]\n",
    "# testData = dataInstrument1[\"price\"][225:]\n",
    "\n",
    "# p = range(30, 31, 1)\n",
    "# d = q = range(0, 2)\n",
    "# pdq = list(itertools.product(p, d, q))\n",
    "# modelAIC = []\n",
    "\n",
    "# for paramlist in pdq:\n",
    "#     arimaModel = ARIMA(trainData, order = paramlist)\n",
    "#     arimaModelFit = arimaModel.fit()\n",
    "#     modelAIC.append(arimaModelFit.aic)\n",
    "\n",
    "# for i in range(len(modelAIC)):\n",
    "#     if list(modelAIC == min(modelAIC))[i] == True:\n",
    "#         print(pdq[i])"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Training using optimised parameters\n",
    "\n",
    "trainData = dataInstrument1[\"price\"][:225]\n",
    "testData = dataInstrument1[\"price\"][225:]\n",
    "arimaModel = ARIMA(trainData, order = (30, 1, 0))\n",
    "arimaModelFit = arimaModel.fit()\n",
    "predictions = arimaModelFit.forecast(steps = 25)\n",
    "\n",
    "testData.plot()\n",
    "predictions.plot(color = \"red\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "source": [
    "## Modern Portfolio Theory Implementation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global constants / variables\n",
    "nDays = 250\n",
    "nInst = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads in first 250 days' data into numpy array givenPrices\n",
    "# Input: N/A\n",
    "# Output: matrix of price history from training data\n",
    "def readTraining ():\n",
    "    f = open(\"prices250.txt\", \"r\")\n",
    "    givenPrices = []\n",
    "    for line in f:\n",
    "        row = [float(num) for num in line.split()]\n",
    "        givenPrices.append(row)\n",
    "    givenPrices = np.array(givenPrices)\n",
    "    # print(givenPrices.shape)\n",
    "    return givenPrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the price history, output daily percentage price change matrix\n",
    "# Input: givenPrices (price history)\n",
    "# Output: matrix of daily percentage change; dailyPChange[i-1][j-1] = percentage change of instrument j between days i and i-1\n",
    "def dailyPChange (givenPrices):\n",
    "    pChange = []\n",
    "    # loop through each instrument\n",
    "    for inst in givenPrices.T:\n",
    "        pChangeInst = np.zeros(nDays)\n",
    "        for day in range(1, nDays):\n",
    "            pChangeInst[day] = inst[day] / inst[day - 1] - 1\n",
    "        pChange.append(pChangeInst)\n",
    "    pChange = np.array(pChange)\n",
    "    # print(pChange.T.shape)\n",
    "    return pChange.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the daily price changes, output the avg. daily return, SD, variance for each instrument\n",
    "def returnMeasures (pChange):\n",
    "    measures = np.zeros((3, nInst))\n",
    "    measures[0] = [np.average(inst) for inst in pChange.T]\n",
    "    measures[1] = [np.std(inst, ddof=1) for inst in pChange.T]\n",
    "    measures[2] = [np.var(inst, ddof=1) for inst in pChange.T]\n",
    "    return measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the price history, output the excess returns matrix\n",
    "# Input: givenPrices (price history)\n",
    "# Output: matrix of excess returns; excessReturns[i-1][j-1] = excess returns of instrument j on day i\n",
    "def excessReturns (givenPrices):\n",
    "    excessReturns = []\n",
    "    # get the required matrices for further computation\n",
    "    pChange = dailyPChange(givenPrices)\n",
    "    measures = returnMeasures(pChange)\n",
    "\n",
    "    for inst in range(nInst):\n",
    "        instExcess = np.zeros(nDays) \n",
    "        instPChange = (pChange.T)[inst]\n",
    "        for i in range (1, nDays):\n",
    "            instExcess[i] = instPChange[i] - measures[0][inst]\n",
    "        excessReturns.append(instExcess)\n",
    "\n",
    "    excessReturns = np.array(excessReturns)\n",
    "    print(excessReturns.T.shape)\n",
    "    return excessReturns.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excess = excessReturns(readTraining())\n",
    "np.matmul(excess, excess.T)\n",
    "\n",
    "excess.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mooooore helpers\n",
    "# Reads in first 250 days' data into numpy array givenPrices\n",
    "# Input: N/A\n",
    "# Output: matrix of price history from training data\n",
    "def readTraining ():\n",
    "    f = open(\"prices250.txt\", \"r\")\n",
    "    givenPrices = []\n",
    "    for line in f:\n",
    "        row = [float(num) for num in line.split()]\n",
    "        givenPrices.append(row)\n",
    "    givenPrices = np.array(givenPrices)\n",
    "    # print(givenPrices.shape)\n",
    "    return givenPrices\n",
    "\n",
    "# Given the price history, output daily percentage price change matrix\n",
    "# Input: givenPrices (price history)\n",
    "# Output: matrix of daily percentage change; dailyReturns[i-1][j-1] = percentage change of instrument j between days i and i-1\n",
    "def dailyReturns (givenPrices):\n",
    "    logChange = []\n",
    "    # loop through each instrument\n",
    "    for inst in givenPrices.T:\n",
    "        logChangeInst = np.empty((nDays, 1))\n",
    "        # logChangeInst = np.zeros(nDays)\n",
    "        for day in range(0, nDays - 1):\n",
    "            logChangeInst[day] = np.log(inst[day + 1] / inst[day])\n",
    "        logChange.append(logChangeInst)\n",
    "    logChange = np.array(logChange)\n",
    "    # print(logChange.T.shape)\n",
    "    return logChange.T\n",
    "\n",
    "# Given the daily price changes, output the avg. daily return, SD, variance for each instrument\n",
    "def returnMeasures (dailyReturns):\n",
    "    measures = np.empty((3, nInst))\n",
    "    measures[0] = [np.average(inst) for inst in dailyReturns.T]\n",
    "    measures[1] = [np.std(inst, ddof=1) for inst in dailyReturns.T]\n",
    "    measures[2] = [np.var(inst, ddof=1) for inst in dailyReturns.T]\n",
    "    return measures\n",
    "\n",
    "# Given the price history, output the excess returns matrix\n",
    "# Input: givenPrices (price history)\n",
    "# Output: matrix of excess returns; excessReturns[i-1][j-1] = excess returns of instrument j on day i\n",
    "def excessReturns (givenPrices):\n",
    "    excessReturns = []\n",
    "    # get the required matrices for further computation\n",
    "    Returns = dailyReturns(givenPrices)\n",
    "    measures = returnMeasures(Returns)\n",
    "\n",
    "    for inst in range(nInst):\n",
    "        instExcess = np.empty(nDays - 1) \n",
    "        instReturns = (Returns.T)[inst]\n",
    "        for i in range (0, nDays - 1):\n",
    "            instExcess[i] = instReturns[i] - measures[0][inst]\n",
    "        excessReturns.append(instExcess)\n",
    "\n",
    "    excessReturns = np.array(excessReturns)\n",
    "    print(excessReturns.T.shape)\n",
    "    return excessReturns.T\n",
    "\n",
    "# Calculate the variance covariance matrix\n",
    "# Input: excess returns\n",
    "# Output: variance covariance matrix\n",
    "def varCov (givenExcess):\n",
    "    varCovMat = np.matmul(givenExcess.T, givenExcess)/(249 - 1) # -1 because sample std\n",
    "    return varCovMat\n",
    "\n",
    "# Calculate the scaled variance covariance matrix\n",
    "# Input: variance covariance matrix\n",
    "# Output: scaled variance covariance matrix\n",
    "def sigma (varCovMat):\n",
    "    sigmaMat = varCovMat*250\n",
    "    return sigmaMat\n",
    "\n",
    "# Calculate weights\n",
    "# Input: \n",
    "# Output: weights\n",
    "def getWeights(returns, sigma, targetReturn):\n",
    "    ones = np.ones(nInst)\n",
    "    A = np.matmul(np.matmul(ones, np.linalg.inv(sigma)), ones.T)\n",
    "    B = np.matmul(np.matmul(ones, np.linalg.inv(sigma)), returns.T)\n",
    "    C = np.matmul(np.matmul(returns, np.linalg.inv(sigma)), returns.T)\n",
    "    delta = A * C - B**2\n",
    "    lam = (C - targetReturn*B)/delta\n",
    "    gam = (targetReturn*A - B)/delta\n",
    "\n",
    "    weightsTerm1 = lam * np.matmul(np.linalg.inv(sigma), ones.T)\n",
    "    weightsTerm2 = gam * np.matmul(np.linalg.inv(sigma), returns.T)\n",
    "    weights = weightsTerm1 + weightsTerm2\n",
    "    return(weights)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "returns = returnMeasures(dailyReturns(readTraining()))[0]*250\n",
    "sigma = sigma(varCov(excessReturns(readTraining())))\n",
    "targetReturn = 0.05\n",
    "getWeights(returns, sigma, targetReturn)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.argwhere(np.isnan(sigma))"
   ]
  }
 ]
}